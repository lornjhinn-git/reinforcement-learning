{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'crypto'\n",
    "engine = create_engine(f'postgresql://postgres:postgres@localhost:5432/{table_name}')\n",
    "\n",
    "df_raw = pd.read_sql_query('select * from klines',con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5min = df_raw.query(\"period_type == '5min'\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_day_of_week(df):\n",
    "    \"\"\"\n",
    "    Returns the name of the day of the week for the given day number (0-6)\n",
    "    \"\"\"\n",
    "    days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    df['local_numeric_day'] =  df['datetime'].apply(lambda x: (x.weekday()) % 7 + 1)\n",
    "    df['local_day'] =  df['local_numeric_day'].apply(lambda x: days[x-1])\n",
    "    return df \n",
    "\n",
    "\n",
    "def set_action(df, optimum_sell_rewards=15, optimum_buy_rewards=15):\n",
    "    \"\"\"\n",
    "    Adds a new column called 'price_diff' to the given DataFrame,\n",
    "    containing the difference between the current row's close price and\n",
    "    the previous row's close price.\n",
    "    \"\"\"\n",
    "    # Create a new column called 'prev_close' that contains the close price from the previous row\n",
    "    df['prev_close'] = df['close'].shift(1)\n",
    "\n",
    "    # Compute the difference between the current row's close price and the previous row's close price\n",
    "    df['price_diff'] = df['close'] - df['prev_close']\n",
    "    df['sell_rewards'] = df['price_diff'].shift(-1)\n",
    "    df['buy_rewards'] = (df['price_diff'].shift(-1))*-1\n",
    "    df['sell_cumulative_rewards'] = df['sell_rewards'].cumsum()\n",
    "    df['buy_cumulative_rewards'] = df['buy_rewards'].cumsum()\n",
    "    df['actions'] = -1 # default 0 = buy, 1 = sell, -1 = no action\n",
    "    df.loc[df['buy_rewards'] >= 5, 'actions'] = 0\n",
    "    df.loc[df['sell_rewards'] > 5 , 'actions'] = 1\n",
    "    df.loc[df['actions'] == 1, 'one_time_reward'] = df['sell_rewards']\n",
    "    df.loc[df['actions'] == 0, 'one_time_reward'] = df['buy_rewards']\n",
    "    df.loc[df['actions'] == -1, 'one_time_reward'] = 0\n",
    "\n",
    "    # Return the updated DataFrame\n",
    "    return df\n",
    "\n",
    "\n",
    "# normal distribution optimum bin\n",
    "def get_optimal_normal_distribution_num_bins(df):\n",
    "    \"\"\"\n",
    "    Estimates the optimal number of bins for the 'volume_trade' column\n",
    "    of the given DataFrame using the Freedman-Diaconis rule, and returns\n",
    "    the estimated number of bins.\n",
    "    \"\"\"\n",
    "    # Compute the interquartile range of the 'volume_trade' column\n",
    "    q1, q3 = np.percentile(df['volume_trade'], [25, 75])\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # Estimate the optimal bin width using the Freedman-Diaconis rule\n",
    "    bin_width = 2 * iqr / np.cbrt(len(df))\n",
    "\n",
    "    # Compute the estimated number of bins\n",
    "    num_bins = int(np.ceil((df['volume_trade'].max() - df['volume_trade'].min()) / bin_width))\n",
    "\n",
    "    # Return the estimated number of bins\n",
    "    return num_bins\n",
    "\n",
    "\n",
    "# power law optimum bin \n",
    "def get_optimal_pareto_distribution_num_bins(df):\n",
    "    \"\"\"\n",
    "    Estimates the optimal number of bins for the 'volume_trade' column\n",
    "    of the given DataFrame using the Sturges method for power law distributions,\n",
    "    and returns the estimated number of bins.\n",
    "    \"\"\"\n",
    "    # Compute the sample size and the maximum value of the 'volume_trade' column\n",
    "    n = len(df['amount'])\n",
    "    x_max = df['amount'].max()\n",
    "\n",
    "    # Estimate the optimal number of bins using the Sturges method\n",
    "    num_bins = int(np.ceil(np.log2(n) + np.log2(1 + x_max)))\n",
    "\n",
    "    # Return the estimated number of bins\n",
    "    return num_bins\n",
    "\n",
    "\n",
    "def pareto_distribution_bins(df, num_bins):\n",
    "    \"\"\"Creates power law bins for the 'volume_trade' column of the given\n",
    "    DataFrame using the qcut function, and returns the updated DataFrame.\n",
    "    \"\"\"\n",
    "    # Compute the quantiles of the 'volume_trade' column using a power law distribution\n",
    "    quantiles = pd.qcut(df['amount'], num_bins, labels=False, duplicates='drop')\n",
    "\n",
    "    # Add a new column to the DataFrame with the bin labels\n",
    "    df['volume_bins'] = quantiles\n",
    "\n",
    "    # Return the updated DataFrame\n",
    "    return df\n",
    "\n",
    "\n",
    "def encode_time(df):\n",
    "    \"\"\"Encodes the time in the given DataFrame as a string representing the time\n",
    "    in sequential order (hour-minute-second), and returns the updated DataFrame.\n",
    "    \"\"\"\n",
    "    # Convert the 'time' column to a datetime object\n",
    "    df['time'] = pd.to_datetime(df['datetime'])\n",
    "    df['date'] = df['datetime'].dt.date\n",
    "\n",
    "    # Extract the hour, minute, and second from the 'time' column\n",
    "    df['hour'] = df['time'].dt.hour\n",
    "    df['minute'] = df['time'].dt.minute\n",
    "    df['second'] = df['time'].dt.second\n",
    "\n",
    "    # Convert the hour, minute, and second to strings\n",
    "    df['hour_str'] = df['hour'].astype(str).str.zfill(2)\n",
    "    df['minute_str'] = df['minute'].astype(str).str.zfill(2)\n",
    "    df['second_str'] = df['second'].astype(str).str.zfill(2)\n",
    "\n",
    "    # Concatenate the hour, minute, and second strings into a single time string\n",
    "    df['encoded_time'] = df['hour_str'] + '-' + df['minute_str'] + '-' + df['second_str']\n",
    "\n",
    "    # Drop the original hour, minute, and second columns\n",
    "    df = df.drop(['hour', 'minute', 'second', 'hour_str', 'minute_str', 'second_str'], axis=1)\n",
    "\n",
    "    # Return the updated DataFrame with the encoded time string\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5min = get_day_of_week(df_5min)\n",
    "df_5min = set_action(df_5min)\n",
    "df_5min = pareto_distribution_bins(df_5min, get_optimal_pareto_distribution_num_bins(df_5min))\n",
    "df_5min = encode_time(df_5min)\n",
    "df_5min.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = df_5min[['datetime', 'encoded_time', 'vol', 'amount', 'average_period_price']].drop_duplicates()\n",
    "df_check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5min.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the rows of the DataFrame\n",
    "\n",
    "price_table = np.zeros((5,7,288))\n",
    "\n",
    "for index, row in df_5min.iterrows():\n",
    "    week_index = row['week_of_month']-1\n",
    "    day_index = row['local_numeric_day']-1\n",
    "    time_index = row['label_encoded_time']-1\n",
    "    value = [row['average_period_price']]\n",
    "    price_table[week_index, day_index, time_index] = value\n",
    "\n",
    "price_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5min[['date', 'local_day']].groupby(\"local_day\").nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_5min.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state space\n",
    "num_days = df['local_numeric_day'].nunique()\n",
    "num_times = df['time'].nunique()\n",
    "num_volume_bins = df['volume_bins'].nunique()\n",
    "state_space = np.zeros((num_days, num_times))\n",
    "train_split = 0.8\n",
    "\n",
    "\n",
    "# Define the action space\n",
    "num_action = df['actions'].nunique()\n",
    "action_space = np.zeros((num_volume_bins, num_action))\n",
    "\n",
    "\n",
    "# Initialize the Q-values\n",
    "global Q_star \n",
    "\n",
    "\n",
    "# Initialize learning rate, discount factor, exploration\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "epsilon = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the reward function\n",
    "def reward(price_rewards):\n",
    "    return price_rewards\n",
    "\n",
    "\n",
    "# Define a function to get the current state\n",
    "def get_state(day, time, volume_bins, action):\n",
    "    # concatenate scalar values into a numpy array\n",
    "    state = np.array((time, day, volume_bins, action))\n",
    "    print(\"Get state:\", type(state), state.shape, state, state[0], state[1], state[2], state[3])\n",
    "    return state\n",
    "\n",
    "\n",
    "def choose_action(state):\n",
    "    print(\"Choose action state:\", type(state), state, state.shape)\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        # Randomly choose an action\n",
    "        action = np.random.choice((0, num_action-1))\n",
    "    else:\n",
    "        # Choose the action with highest Q value\n",
    "        action = np.argmax(Q[state[0]][state[1]][state[2]])\n",
    "    return action\n",
    "\n",
    "\n",
    "# Generate the sample data\n",
    "def generate_sample(df):\n",
    "\n",
    "    cols = ['local_numeric_day', 'encoded_time', 'volume_bins', 'actions']\n",
    "    df = df[cols]\n",
    "\n",
    "    # Get states as tuple\n",
    "    state_tuple = create_state_tuple(df)\n",
    "\n",
    "    # Initiate Q table \n",
    "    global Q_star \n",
    "    Q_star = np.zeros((state_tuple))\n",
    "\n",
    "    train_data = df[:math.floor(df.shape[0]*train_split)].to_numpy()\n",
    "    test_data = df[train_data.shape[0]:].to_numpy()\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "\n",
    "def train_sarsa(train_data):\n",
    "    # Define variables to track performance validation\n",
    "    prev_avg_reward = -1000\n",
    "    avg_reward = 0\n",
    "    num_episodes = 0\n",
    "    \n",
    "    # Train for multiple episodes until convergence\n",
    "    while abs(avg_reward - prev_avg_reward) > 0.001:\n",
    "        prev_avg_reward = avg_reward\n",
    "        total_reward = 0\n",
    "        print(\"Start SARSA\")\n",
    "        \n",
    "        # Loop through all training data\n",
    "        for i in range(len(train_data)-1):\n",
    "            # Get current state and action\n",
    "            state = get_state(train_data[i][0], train_data[i][1], train_data[i][2], train_data[i][3])\n",
    "            # action = choose_action(state)\n",
    "            \n",
    "            # Get next state and reward\n",
    "            # next_state = get_state(train_data[i+1][0], train_data[i+1][1], train_data[i+1][2], train_data[i+1][3])\n",
    "            reward = train_data[i+1][-1] * 0.1\n",
    "            \n",
    "            # Choose next action based on epsilon-greedy policy\n",
    "            # next_action = choose_action(next_state)\n",
    "            \n",
    "            # Update Q table\n",
    "            td_error = reward + gamma * Q[i+1][-1][-1] - Q[i][-1][-1]\n",
    "            Q[i][-1][-1] += alpha * td_error\n",
    "        \n",
    "            total_reward += reward\n",
    "        \n",
    "        # Calculate average reward for the current episode\n",
    "        avg_reward = total_reward / len(train_data)\n",
    "        num_episodes += 1\n",
    "        print(\"Episode:\", num_episodes, \"Average Reward:\", avg_reward)\n",
    "    \n",
    "    return Q\n",
    "\n",
    "\n",
    "def create_state_tuple(df_train):\n",
    "    '''\n",
    "    Automatically initiate state tuple based on the number of unique\n",
    "    values in each state (features) from the given dataframe to ease the initiation of Q table\n",
    "    '''\n",
    "    state_list = []\n",
    "\n",
    "    state_list.append(df_train.shape[0])\n",
    "    for col in df_train:\n",
    "        state_list.append(df_train[col].nunique())\n",
    "\n",
    "    state_tuple = tuple(state_list)\n",
    "\n",
    "    return state_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = df['one_time_reward'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import project.SARSA_one_state as SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dict = {\n",
    "\t'buy': 0,\n",
    "\t'sell': 1,\n",
    "\t'no_action': 2\n",
    "}\n",
    "\n",
    "\n",
    "def policy(Q, sarsa_agent, state, epsilon = 0.1, verbose = False) -> (int, float): \n",
    "\tbest_action = None\n",
    "\tbest_value = float('-inf')\n",
    "\t\n",
    "\t# update allowed actions everytime based on agent current holding unit \n",
    "\tif sarsa_agent.isHolding == False: # indicate can buy/no action but cannot sell\n",
    "\t\tallowed_actions = ['buy', 'no_action']\n",
    "\telse:\n",
    "\t\tallowed_actions = ['sell', 'no_action']\n",
    "\n",
    "\trandom.shuffle(allowed_actions)\n",
    "\n",
    "\tfor action in allowed_actions:\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(f\"Holding: {sarsa_agent.isHolding}\")\n",
    "\t\t\tprint(f'action: {action}')\n",
    "\t\t\tprint(f'value: {Q[state][action_dict.get(action)]} vs best_value: {best_value}')\n",
    "\t\t\tprint(f'new best action: {action}')\n",
    "\t\tif Q[state][action_dict.get(action)] > best_value:\n",
    "\t\t\tbest_action = action_dict.get(action)\n",
    "\t\t\tbest_value = Q[state][best_action]\n",
    "\t\t\t\t\n",
    "\tr_var = random.random()\n",
    "\tif r_var < epsilon:\n",
    "\t\tif verbose:\n",
    "\t\t\tprint(f'Choosing random action')\n",
    "\t\tbest_action = action_dict.get(random.choice(allowed_actions))\n",
    "\t\tbest_value = Q[state][best_action]\n",
    "\t\t\n",
    "\tif verbose:\n",
    "\t\tprint(f'Final action: {best_action}\\n')\n",
    "\n",
    "\treturn best_action, best_value\n",
    "\n",
    "\n",
    "# Update Q-value for a state-action pair based on observed rewards and estimated future Q-values\n",
    "def update_q_value(state:tuple, action:int, rewards:list, rewards_value:float, next_state:tuple, next_action:int, verbose=False):\n",
    "\n",
    "\tif verbose == True:\n",
    "\t\tprint(f\"State: {state}, Action: {action}, Rewards: {rewards}, Next_state: {next_state}, Next_action: {next_action}\")\n",
    "\t\t\n",
    "\t# Compute the updated Q-value using the SARSA update equation\n",
    "\tcurrent_q = Q[state][action_dict.get(action)]\n",
    "\n",
    "\t# Additional reward if have been making profit of at least 20 usd\n",
    "\tif sum(rewards) >= 20: current_q += 100\n",
    "\tnext_q = Q[next_state][action_dict.get(next_action)]\n",
    "\tnew_q = current_q + lr * (rewards_value + GAMMA * next_q - current_q)\n",
    "    \n",
    "    # Update the Q-value in the Q-table\n",
    "\tQ[state][action_dict.get(action)] = new_q\n",
    "\t\n",
    "    # Check if the (state, action) pair exists in the Q-table\n",
    "    # if (state, action) not in Q:\n",
    "    #     Q[(state, action)] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for episode in range(num_episodes):\n",
    "steps = []\n",
    "rewards_list = []\n",
    "steps_list = []\n",
    "\n",
    "\n",
    "num_episodes = 10000000\n",
    "num_steps_per_episode = 10\n",
    "total_rewards = 0\n",
    "GAMMA = 0.9\n",
    "\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    current_state = 0  # Starting state\n",
    "    action, action_value = policy(Q, sarsa_agent, current_state, epsilon，)\n",
    "    # update upcoming allowed actions\n",
    "    if action == 0:\n",
    "        sarsa_agent.isHolding = True\n",
    "    if action == 1:\n",
    "        sarsa_agent.isHolding = False\n",
    "    total_rewards = 0\n",
    "\n",
    "    while (current_state != Q.shape[0] - 1):\n",
    "        rewards = reward_table[current_state][action]\n",
    "        total_rewards += rewards\n",
    "        steps.append(action)\n",
    "        next_state = current_state + 1 \n",
    "        next_action, next_action_value = policy(Q, sarsa_agent, next_state, epsilon)\n",
    "        update_q_value(current_state, action, rewards, next_state, next_action)\n",
    "\n",
    "        # print(f'After update:, action: {action}, action_value : {action_value}, next_action: {next_action}, next_action_value: {next_action_value}\\n')\n",
    "        # update upcoming allowed actions\n",
    "        if next_action == 0:\n",
    "            sarsa_agent.isHolding = True\n",
    "        if next_action == 1:\n",
    "            sarsa_agent.isHolding = False\n",
    "\n",
    "        current_state = next_state\n",
    "        action = next_action \n",
    "        action_value = next_action_value\n",
    "\n",
    "    rewards_list.append(total_rewards)\n",
    "    steps_list.append(steps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Perform price and volume aggregation for monthly daily basis reward table***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the trade volumes here originally is \"amount\", total usd price is \"vol\"\n",
    "# will rename after retrieved from the dataframe\n",
    "desired_col = [ \n",
    "    'date', \n",
    "    'time', \n",
    "    'local_numeric_day', \n",
    "    'amount',\n",
    "    'vol',\n",
    "    'sell_rewards', \n",
    "    'buy_rewards', \n",
    "    'sell_cumulative_rewards', \n",
    "    'buy_cumulative_rewards',\n",
    "    'actions',\n",
    "    'volume_bins',\n",
    "    'encoded_time'\n",
    "]\n",
    "\n",
    "renamed_col = [ \n",
    "    'date', \n",
    "    'time', \n",
    "    'local_numeric_day', \n",
    "    'trade_volumes',\n",
    "    'trade_total_price',\n",
    "    'sell_rewards', \n",
    "    'buy_rewards', \n",
    "    'sell_cumulative_rewards', \n",
    "    'buy_cumulative_rewards',\n",
    "    'actions',\n",
    "    'volume_bins',\n",
    "    'encoded_time'\n",
    "]\n",
    "\n",
    "\n",
    "df_volumes = df[desired_col]\n",
    "df_volumes.columns = renamed_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date \n",
    "\n",
    "def convert_to_first_day_of_month(df, date_column_name):\n",
    "    # convert to datetime format\n",
    "    starting_month_list = df[date_column_name].apply(lambda x: date(x.year, x.month, 1))\n",
    "    return starting_month_list\n",
    "\n",
    "def get_week_of_month(df, date_column_name) -> list:\n",
    "\n",
    "    def compute_week_of_month(date_value):\n",
    "        first_day = date(date_value.year, date_value.month, 1)\n",
    "        offset = (date_value.weekday() + 1 - first_day.weekday()) % 7\n",
    "        week_of_month = (date_value.day + offset - 1) // 7 + 1\n",
    "        return week_of_month\n",
    "\n",
    "    week_of_month_list = df[date_column_name].apply(lambda x: compute_week_of_month(x))\n",
    "\n",
    "    return week_of_month_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_volumes['starting_month'] = convert_to_first_day_of_month(df, 'date')\n",
    "df_volumes['week_of_month'] = get_week_of_month(df, 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_volumes.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start aggregating the trading data**\n",
    "\n",
    "***Based on year, month, day, time to see the max, min, average, median, sd of the price and volumes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_cols = ['week_of_month', 'local_numeric_day', 'encoded_time', 'trade_volumes']\n",
    "price_cols = ['week_of_month', 'local_numeric_day', 'encoded_time', 'trade_volumes', 'trade_total_price']\n",
    "reward_cols = ['week_of_month', 'local_numeric_day', 'encoded_time', 'sell_rewards', 'buy_rewards', 'actions']\n",
    "\n",
    "groupby_keys = ['week_of_month', 'local_numeric_day', 'encoded_time']\n",
    "\n",
    "df_volume_stats = df_volumes[volume_cols].groupby(groupby_keys).describe().reset_index()\n",
    "\n",
    "df_price = df_volumes[price_cols].groupby(groupby_keys).sum()\n",
    "df_price['daily_average_trade_total_price'] = df_price['trade_total_price'] / df_price['trade_volumes']\n",
    "df_price = df_price.drop(columns=['trade_volumes', 'trade_total_price'])\n",
    "df_price_stats = df_price.groupby(groupby_keys).mean()\n",
    "\n",
    "df_reward_stats = df_volumes[reward_cols[:-1]].groupby(groupby_keys).describe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_volume_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reward_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reward_stats[['week_of_month', 'local_numeric_day', 'encoded_time']]\\\n",
    ".reset_index()\\\n",
    ".groupby(['week_of_month', 'local_numeric_day'])\\\n",
    ".nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Create nested reward table***\n",
    "\n",
    "***Keep the df_price_stats and df_volume_stats for reference***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reward_stats.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Start creating nested reward table from here***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sell_rewards = df_reward_stats['sell_rewards'][['mean']].copy()\n",
    "df_buy_rewards = df_reward_stats['buy_rewards'][['mean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sell_rewards.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_cols = ['sell_rewards']\n",
    "buy_cols = ['buy_rewards']\n",
    "df_sell_rewards.columns = sell_cols\n",
    "df_buy_rewards.columns = buy_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sell_rewards.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buy_rewards.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_nested_rewards = pd.merge([df_reward_stats[['week_of_month', 'local_numeric_day', 'encoded_time']], df_sell_rewards, df_buy_rewards],).reset_index()\n",
    "df_nested_rewards = pd.concat([df_reward_stats[['week_of_month', 'local_numeric_day', 'encoded_time']], df_sell_rewards, df_buy_rewards], axis=1)\n",
    "\n",
    "# rename column to remove the tuple-like hierachy syntax for easier retrieve\n",
    "rename_cols = ['week_of_month', 'local_numeric_day', 'encoded_time', 'sell_rewards', 'buy_rewards']\n",
    "df_nested_rewards.columns = rename_cols\n",
    "df_nested_rewards.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom aggregation function to fill in values based on conditions\n",
    "def fill_values(column):\n",
    "    if column[column > 0].empty:\n",
    "        return None\n",
    "    return column[column > 0].values[0]\n",
    "\n",
    "# Pivot the DataFrame\n",
    "df_pivoted_rewards = pd.pivot_table(df_nested_rewards, values=['sell_rewards', 'buy_rewards'], index=['week_of_month', 'local_numeric_day', 'encoded_time'],\n",
    "                            aggfunc=fill_values).reset_index()\n",
    "df_pivoted_rewards = df_pivoted_rewards.rename(columns={'sell_rewards': 'sell_action', 'buy_rewards': 'buy_action'})\n",
    "df_pivoted_rewards.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign reverse action reward for NaN value \n",
    "df_pivoted_rewards['buy_action'] = df_pivoted_rewards['buy_action'].fillna(df_pivoted_rewards['sell_action']*-1)\n",
    "df_pivoted_rewards['sell_action'] = df_pivoted_rewards['sell_action'].fillna(df_pivoted_rewards['buy_action']*-1)\n",
    "df_pivoted_rewards.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in no action reward value \n",
    "df_pivoted_rewards['no_action'] = 0\n",
    "df_pivoted_rewards.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform encoded time into scalar value for easier indexing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df_pivoted_rewards['label_encoded_time'] = encoder.fit_transform(df_pivoted_rewards[['encoded_time']])\n",
    "df_pivoted_rewards.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivoted_rewards.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivoted_rewards.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique value of each column for each state \n",
    "state_unique_counts = df_pivoted_rewards.nunique()\n",
    "\n",
    "# initialize shape size\n",
    "state_array_shape = tuple(state_unique_counts[:3])\n",
    "# add 3 unique actions \n",
    "state_array_shape += (num_action ,)\n",
    "print(\"State array shape:\", state_array_shape)\n",
    "\n",
    "# create the array with the initialized shape size \n",
    "state_array = np.zeros(state_array_shape)\n",
    "\n",
    "# start padding reward value into each state respectively\n",
    "# Iterate over the rows of the DataFrame\n",
    "for index, row in df_pivoted_rewards.iterrows():\n",
    "    week_index = row['week_of_month']-1\n",
    "    day_index = row['local_numeric_day']-1\n",
    "    time_index = row['label_encoded_time']-1\n",
    "    value = [row['buy_action'], row['sell_action'], row['no_action']]\n",
    "    state_array[week_index, day_index, time_index] = value\n",
    "\n",
    "state_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign state array to be reward array for easier reference\n",
    "reward_table = state_array.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over dimensions a, b, c sequentially\n",
    "# 27/6/2023: tried np.diter but doesnt want to waste more time as there are more parameters to discover but knew that this will reduce the computation time complexity\n",
    "# for now use a simple nested loops first\n",
    "# in future when data is more then explore np.diter\n",
    "for month in range(reward_table.shape[0]):\n",
    "    for day in range(reward_table.shape[1]):\n",
    "        for time in range(reward_table.shape[2]):\n",
    "            state = (month, day, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start modifying the SARSA nested state iteration from here\n",
    "# Training loop\n",
    "# for episode in range(num_episodes):\n",
    "\n",
    "# Training loop\n",
    "import project.SARSA_one_state as SARSA\n",
    "\n",
    "num_states = df['encoded_time'].nunique()\n",
    "num_actions = df['actions'].nunique()\n",
    "lr = 0.005\n",
    "discount_factor = 0.1\n",
    "epsilon = 0.1\n",
    "# print(num_states, num_actions)\n",
    "\n",
    "sarsa_agent = SARSA.SARSAAgent(\n",
    "    df,\n",
    "    learning_rate=lr,\n",
    "    discount_factor=discount_factor,\n",
    "    epsilon=epsilon\n",
    ")\n",
    "\n",
    "global Q \n",
    "sarsa_agent.initialize_q_table(df)\n",
    "Q = np.zeros(reward_table.shape)\n",
    "print(Q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environments_list = []\n",
    "total_rewards_list = []\n",
    "rewards_list = []\n",
    "steps_list = []\n",
    "num_episodes = 10000\n",
    "# num_steps_per_episode = 1000\n",
    "GAMMA = 0.9\n",
    "isVerbose = False\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "\n",
    "    print(\"\\nEpisode:\", episode)\n",
    "\n",
    "    # initialize cumulative rewards\n",
    "    total_rewards = 0\n",
    "    steps = []\n",
    "    environments = []\n",
    "    rewards = []\n",
    "\n",
    "    current_state = (0,0,0) # Starting state\n",
    "    action, action_value = policy(Q, sarsa_agent, current_state, epsilon, verbose=isVerbose)\n",
    "    # update upcoming allowed actions\n",
    "    if action == 0:\n",
    "        sarsa_agent.isHolding = True\n",
    "    else:\n",
    "        sarsa_agent.isHolding = False\n",
    "\n",
    "    rewards_value = reward_table[current_state][action]\n",
    "    total_rewards += rewards_value\n",
    "\n",
    "    steps.append(action)\n",
    "    rewards.append(rewards_value)\n",
    "    environments.append(current_state)\n",
    "\n",
    "    # when current state has not iterate until the last row of Q table\n",
    "    # while (current_state != (reward_table.shape[0],reward_table.shape[1],reward_table.shape[2])):\n",
    "\n",
    "    for month in range(reward_table.shape[0]):\n",
    "        for day in range(reward_table.shape[1]):\n",
    "            for time in range(reward_table.shape[2]):\n",
    "\n",
    "                # when iterating (0,0) start from (0,0,1) to (0,0,287) because (0,0,0) already initialized on top\n",
    "                if current_state[0] == 0 and current_state[1] == 0:\n",
    "                    current_state = [month, day, time + 1]\n",
    "                else:\n",
    "                    current_state = [month, day, time]\n",
    "\n",
    "                current_state = tuple(current_state)\n",
    "                # print(\"Current state:\", current_state)\n",
    "                # print(\"Current action:\", action, action_value)\n",
    "\n",
    "                rewards_value = reward_table[current_state][action]\n",
    "                total_rewards += rewards_value\n",
    "\n",
    "                # print(\"Total rewards:\", total_rewards)\n",
    "\n",
    "                steps.append(action)\n",
    "                rewards.append(rewards_value)\n",
    "                environments.append(current_state)\n",
    "\n",
    "                # if not last row of state then + 1 else move up 1 level then + 1\n",
    "                if current_state[2] < reward_table.shape[2] - 1:\n",
    "                    next_state = [current_state[0], current_state[1], current_state[2] + 1]\n",
    "                    # print(\"In time:\", current_state, next_state)\n",
    "                elif reward_table.shape[2] - 1 == current_state[2] and current_state[1] < reward_table.shape[1] - 1:\n",
    "                    next_state = [current_state[0], current_state[1] + 1, current_state[2]]\n",
    "                    # print(\"In day:\", current_state,  next_state)\n",
    "                elif current_state[0] < reward_table.shape[0] - 1:\n",
    "                    next_state = [current_state[0] + 1, current_state[1], current_state[2]]\n",
    "                    # print(\"In month:\", current_state, next_state)\n",
    "                \n",
    "                next_state = tuple(next_state)\n",
    "                next_action, next_action_value = policy(Q, sarsa_agent, next_state, epsilon, verbose=isVerbose)\n",
    "\n",
    "                #print(\"End:\", current_state, action, rewards, next_state, next_action)\n",
    "                update_q_value(current_state, action, rewards, rewards_value, next_state, next_action, verbose=False)\n",
    "\n",
    "                # print(f'After update:, action: {action}, action_value : {action_value}, next_action: {next_action}, next_action_value: {next_action_value}\\n')\n",
    "                # update upcoming allowed actions\n",
    "                if next_action == 0:\n",
    "                    sarsa_agent.isHolding = True\n",
    "                if next_action == 1:\n",
    "                    sarsa_agent.isHolding = False\n",
    "\n",
    "                current_state = next_state\n",
    "                action = next_action \n",
    "                action_value = next_action_value\n",
    "\n",
    "    total_rewards_list.append(sum(rewards))\n",
    "    rewards_list.append(rewards)\n",
    "    steps_list.append(steps)\n",
    "    environments_list.append(environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('sarsa_crypto.pickle', 'wb') as file:\n",
    "#     pickle.dump((Q, reward_table, rewards_list, steps_list), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = pd.DataFrame(total_rewards_list, columns=['rewards'])\n",
    "df_check.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rewards_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value_index = total_rewards_list.index(max(total_rewards_list))\n",
    "worst_value_index = total_rewards_list.index(min(total_rewards_list))\n",
    "\n",
    "print(max_value_index)\n",
    "print(worst_value_index)\n",
    "print(max(total_rewards_list))\n",
    "print(min(total_rewards_list))\n",
    "print(\"Max step list:\", steps_list[max_value_index])\n",
    "print(\"Bad step list:\", steps_list[worst_value_index])\n",
    "\n",
    "# Check if each row has different values\n",
    "is_different = np.all(np.diff(Q, axis=1), axis=1)\n",
    "\n",
    "# Display the result\n",
    "#print(is_different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_list[worst_value_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_list[max_value_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_environments = pd.DataFrame(environments_list)\n",
    "# df_environments.T.head(20)\n",
    "\n",
    "# df_steps = pd.DataFrame(steps_list)\n",
    "# df_steps.T.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(rewards_list[max_value_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(rewards_list[worst_value_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the main action difference between max and worst step at what timestep\n",
    "df_compare = pd.DataFrame(steps_list[max_value_index], columns=['max_steps_action'])\n",
    "df_compare['worst_steps_action'] = steps_list[worst_value_index]\n",
    "df_compare['is_same'] = df_compare['max_steps_action'].equals(df_compare['worst_steps_action'])\n",
    "df_compare.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the first action where both are difference\n",
    "df_compare[df_compare['is_same'] != True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate why same action but giving different reward value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('sarsa_crypto.pickle', 'rb') as file:\n",
    "    loaded_data = pickle.load(file)\n",
    "\n",
    "print(loaded_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(rewards_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rewards_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "\n",
    "joblib.dump(Q, 'sarsa_crypto.joblib')\n",
    "# [Q, total_rewards_list, rewards_list, steps_list]\n",
    "\n",
    "# save rewards and steps list\n",
    "with open('rewards.txt', 'w') as file:\n",
    "    # Convert each element in the list to a string and write it to the file\n",
    "    for item in rewards_list:\n",
    "        file.write(str(item) + '\\n')\n",
    "\n",
    "with open('steps.txt', 'w') as file:\n",
    "    # Convert each element in the list to a string and write it to the file\n",
    "    for item in steps_list:\n",
    "        file.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "\n",
    "def load_large_text_file(file_path):\n",
    "    data_list = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data_list.append(line.rstrip('\\n'))\n",
    "    return data_list\n",
    "\n",
    "Q = joblib.load('sarsa_crypto.joblib')\n",
    "rewards_list = load_large_text_file('rewards.txt')\n",
    "steps_list = load_large_text_file('steps.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.shape "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Validate the trained SARSA performance***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained SARSA model\n",
    "model = joblib.load('sarsa_crypto.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5min.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and preprocess your test data\n",
    "test_data = load_test_data()  # Replace with your code to load test data\n",
    "preprocessed_data = preprocess(test_data)  # Replace with your code to preprocess the data\n",
    "\n",
    "# Evaluate model performance on test data\n",
    "total_rewards = 0\n",
    "num_episodes = len(preprocessed_data)\n",
    "\n",
    "for episode in preprocessed_data:\n",
    "    state = episode['state']\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = model.predict(state)\n",
    "        next_state, reward, done = environment.step(action)\n",
    "        episode_reward += reward\n",
    "        state = next_state\n",
    "\n",
    "    total_rewards += episode_reward\n",
    "\n",
    "average_reward = total_rewards / num_episodes\n",
    "print(f\"Average reward on test data: {average_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParentSARSA:\n",
    "    def __init__(self, verbose=True):\n",
    "        self.learning_rate: Optional[float] = 0.005\n",
    "        self.discount_factor: Optional[float] = 0.1\n",
    "        self.epsilon: Optional[float] = 0.1\n",
    "        self.gamma: Optional[float] = 0.9\n",
    "        self.num_episodes: Optional[int] = 100\n",
    "        self.data: Optional[pd.Dataframe] = None\n",
    "        self.Q: Optional[np.array] = None\n",
    "        self.reward_table: Optional[np.array] = None\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Parent SARSA inherited!\")\n",
    "            print(\"Parent attributes:\", self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarsa = ParentSARSA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "hold_array = np.array([[10, 20]])\n",
    "\n",
    "hold_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_array[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "isHolding = random.random() < 0.5\n",
    "isHolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state = (0,0,0,0)\n",
    "current_state = (1,) + current_state[1:]\n",
    "current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(2):\n",
    "\n",
    "    print(\"\\nEpisode:\", episode)\n",
    "\n",
    "    # initialize cumulative rewards\n",
    "    total_rewards = 0\n",
    "    steps = []\n",
    "    environments = []\n",
    "    rewards = []\n",
    "\n",
    "    # Randomize the starting state\n",
    "    if random.random() < 0.5: \n",
    "        current_state = (0,0,0,0)\n",
    "    else:\n",
    "        current_state = (1,0,0,0)\n",
    "\n",
    "    # the recommended action will be choosen from the allowed actions listS\n",
    "    action, action_value = policy(current_state)\n",
    "\n",
    "    # get the reward from the action taken in current state\n",
    "    rewards_value = Sarsa.reward_table[current_state][action]\n",
    "    total_rewards += rewards_value\n",
    "\n",
    "    # determine the next state based on the current state + action\n",
    "    if action == 0:\n",
    "        Sarsa.isHolding = True\n",
    "        # current_state = (1,) + current_state[1:]\n",
    "    else:\n",
    "        Sarsa.isHolding = False\n",
    "        # current_state = (0,) + current_state[1:]\n",
    "\n",
    "    steps.append(action)\n",
    "    rewards.append(rewards_value)\n",
    "    environments.append(current_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in range(3):\n",
    "    for day in range(2):\n",
    "        for time in range(1):\n",
    "            print(month, day, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4]\n",
    "\n",
    "a[3] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1:] == [2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (0,1,2,3)\n",
    "a[1:] == [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (0,0,0,0)\n",
    "current_state = list(a)\n",
    "current_state[3] = 1\n",
    "next_state = tuple(current_state)\n",
    "\n",
    "next_state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2,5,7,288,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for month in range(0, 5):\n",
    "    for day in range(0, 7):\n",
    "        for time in range(0, 288):\n",
    "            print(month, day, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "def log_print(*args, **kwargs):\n",
    "    with open('print_log.txt', 'a') as f:\n",
    "        print(*args, **kwargs, file=f)\n",
    "\n",
    "# Redirect stdout to the log_print function\n",
    "sys.stdout = log_print\n",
    "\n",
    "# Your code here\n",
    "print(\"Hello, this will be logged in print_log.txt\")\n",
    "print(\"You can add any print statements here\")\n",
    "\n",
    "# Restore stdout to the original stream\n",
    "sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "Q = joblib.load('sarsa_crypto.joblib')\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "df_train = pd.read_csv(\"train_data.csv\")\n",
    "df_test = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "df_train = pd.read_csv(\"train_data.csv\")\n",
    "df_test = pd.read_csv(\"test_data.csv\")\n",
    "\n",
    "def get_day_of_week(df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns the name of the day of the week for the given day number (0-6)\n",
    "    \"\"\"\n",
    "    days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    df['local_numeric_day'] =  df['datetime'].apply(lambda x: (x.weekday()) % 7 + 1)\n",
    "    df['local_day'] =  df['local_numeric_day'].apply(lambda x: days[x-1])\n",
    "    return df \n",
    "\n",
    "\n",
    "def test_get_day_of_week(df_train, df_test):\n",
    "    df_days = pd.DataFrame({'local_numeric_day': [1,2,3,4,5,6,7], 'local_day':['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']})\n",
    "    cols = ['local_numeric_day', 'local_day']\n",
    "    try:\n",
    "        df_train = get_day_of_week(df_train).sort_values(by='local_numeric_day')[cols]\n",
    "        df_test = get_day_of_week(df_test).sort_values(by='local_numeric_day')[cols]\n",
    "        assert df_days == df_train == df_test\n",
    "    except AttributeError: # str type 'datetime' column doesnt have datetime built-in function\n",
    "        try:\n",
    "            df_train['datetime'] = df_train['datetime'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "            df_test['datetime'] = df_test['datetime'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "            df_train = get_day_of_week(df_train).sort_values(by='local_numeric_day')[cols]\n",
    "            df_test = get_day_of_week(df_test).sort_values(by='local_numeric_day')[cols]\n",
    "            assert df_days == df_train == df_test\n",
    "        except (ValueError, KeyError):\n",
    "            raise ValueError(\"Invalid date format. The date value must be either in datetime format or a string in the format 'YYYY-MM-DD HH:MM:SS'.\")                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_get_day_of_week(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train_data.csv\")\n",
    "df_train['datetime'] = df_train['datetime'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "df_train['local_numeric_day'] =  df_train['datetime'].apply(lambda x: (x.weekday()) % 7 + 1)\n",
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pandas.testing import assert_frame_equal\n",
    "\n",
    "print(\"Start testing\")\n",
    "\n",
    "class Preprocessor():\n",
    "    def get_day_of_week(self, df) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Returns the name of the day of the week for the given day number (0-6)\n",
    "        \"\"\"\n",
    "        days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "        df['local_numeric_day'] =  df['datetime'].apply(lambda x: (x.weekday()) % 7 + 1)\n",
    "        df['local_day'] =  df['local_numeric_day'].apply(lambda x: days[x-1])\n",
    "        return df \n",
    "    \n",
    "\n",
    "    def set_action(df, optimum_sell_rewards=15, optimum_buy_rewards=15) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Adds a new column called 'price_diff' to the given DataFrame,\n",
    "        containing the difference between the current row's close price and\n",
    "        the previous row's close price.\n",
    "        \"\"\"\n",
    "        # Create a new column called 'prev_close' that contains the close price from the previous row\n",
    "        df['prev_close'] = df['close'].shift(1)\n",
    "\n",
    "        # Compute the difference between the current row's close price and the previous row's close price\n",
    "        df['price_diff'] = df['close'] - df['prev_close']\n",
    "        df['sell_rewards'] = df['price_diff'].shift(-1)\n",
    "        df['buy_rewards'] = (df['price_diff'].shift(-1))*-1\n",
    "        df['sell_cumulative_rewards'] = df['sell_rewards'].cumsum()\n",
    "        df['buy_cumulative_rewards'] = df['buy_rewards'].cumsum()\n",
    "        df['actions'] = -1 # default 0 = buy, 1 = sell, -1 = no action\n",
    "        df.loc[df['buy_rewards'] >= 5, 'actions'] = 0\n",
    "        df.loc[df['sell_rewards'] > 5 , 'actions'] = 1\n",
    "        df.loc[df['actions'] == 1, 'one_time_reward'] = df['sell_rewards']\n",
    "        df.loc[df['actions'] == 0, 'one_time_reward'] = df['buy_rewards']\n",
    "        df.loc[df['actions'] == -1, 'one_time_reward'] = 0\n",
    "\n",
    "        # Return the updated DataFrame\n",
    "        return df\n",
    "\n",
    "\n",
    "    # power law optimum bin \n",
    "    def get_optimal_pareto_distribution_num_bins(df) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Estimates the optimal number of bins for the 'volume_trade' column\n",
    "        of the given DataFrame using the Sturges method for power law distributions,\n",
    "        and returns the estimated number of bins.\n",
    "        \"\"\"\n",
    "        # Compute the sample size and the maximum value of the 'volume_trade' column\n",
    "        n = len(df['amount'])\n",
    "        x_max = df['amount'].max()\n",
    "\n",
    "        # Estimate the optimal number of bins using the Sturges method\n",
    "        num_bins = int(np.ceil(np.log2(n) + np.log2(1 + x_max)))\n",
    "\n",
    "        # Return the estimated number of bins\n",
    "        return num_bins\n",
    "\n",
    "\n",
    "    def pareto_distribution_bins(df) -> pd.DataFrame:\n",
    "        \"\"\"Creates power law bins for the 'volume_trade' column of the given\n",
    "        DataFrame using the qcut function, and returns the updated DataFrame.\n",
    "        \"\"\"\n",
    "\n",
    "        # Compute the optimal number of bins for quantiles splitting\n",
    "        # num_bins = get_optimal_pareto_distribution_num_bins(df)\n",
    "        num_bins = 10\n",
    "\n",
    "        # Compute the quantiles of the 'volume_trade' column using a power law distribution\n",
    "        quantiles = pd.qcut(df['amount'], num_bins, labels=False, duplicates='drop')\n",
    "\n",
    "        # Add a new column to the DataFrame with the bin labels\n",
    "        df['volume_bins'] = quantiles\n",
    "\n",
    "        # Return the updated DataFrame\n",
    "        return df\n",
    "    \n",
    "    def encode_time(df) -> pd.DataFrame:\n",
    "        \"\"\"Encodes the time in the given DataFrame as a string representing the time\n",
    "        in sequential order (hour-minute-second), and returns the updated DataFrame.\n",
    "        \"\"\"\n",
    "        # Convert the 'time' column to a datetime object\n",
    "        df['time'] = pd.to_datetime(df['datetime'])\n",
    "        df['date'] = df['datetime'].dt.date\n",
    "\n",
    "        # Extract the hour, minute, and second from the 'time' column\n",
    "        df['hour'] = df['time'].dt.hour\n",
    "        df['minute'] = df['time'].dt.minute\n",
    "        df['second'] = df['time'].dt.second\n",
    "\n",
    "        # Convert the hour, minute, and second to strings\n",
    "        df['hour_str'] = df['hour'].astype(str).str.zfill(2)\n",
    "        df['minute_str'] = df['minute'].astype(str).str.zfill(2)\n",
    "        df['second_str'] = df['second'].astype(str).str.zfill(2)\n",
    "\n",
    "        # Concatenate the hour, minute, and second strings into a single time string\n",
    "        df['encoded_time'] = df['hour_str'] + '-' + df['minute_str'] + '-' + df['second_str']\n",
    "\n",
    "        # Drop the original hour, minute, and second columns\n",
    "        df = df.drop(['hour', 'minute', 'second', 'hour_str', 'minute_str', 'second_str'], axis=1)\n",
    "\n",
    "        # Return the updated DataFrame with the encoded time string\n",
    "        return df\n",
    "\n",
    "\n",
    "    def convert_to_first_day_of_month(df) -> pd.DataFrame:\n",
    "        # convert to datetime format\n",
    "        date_column_name = 'date'\n",
    "        assign_column_name = 'starting_month'\n",
    "        starting_month_list = df[date_column_name].apply(lambda x: date(x.year, x.month, 1))\n",
    "        df.loc[:, assign_column_name] = starting_month_list\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def get_week_of_month(df) -> pd.DataFrame:\n",
    "\n",
    "        def compute_week_of_month(date_value):\n",
    "            first_day = date(date_value.year, date_value.month, 1)\n",
    "            offset = (date_value.weekday() + 1 - first_day.weekday()) % 7\n",
    "            week_of_month = (date_value.day + offset - 1) // 7 + 1\n",
    "            return week_of_month\n",
    "\n",
    "        date_column_name = 'date'\n",
    "        assign_column_name = 'week_of_month'\n",
    "        week_of_month_list = df[date_column_name].apply(lambda x: compute_week_of_month(x))\n",
    "        df.loc[:, assign_column_name] = week_of_month_list\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def get_daily_average_trade_total_price(df) -> pd.DataFrame:\n",
    "        df = df[Constantor.PRICE_COLS].groupby(Constantor.GROUPBY_KEYS).sum()\n",
    "        df['daily_average_trade_total_price'] = df['trade_total_price'] / df['trade_volumes']\n",
    "        df = df.drop(columns=['trade_volumes', 'trade_total_price'])\n",
    "        return df\n",
    "\n",
    "\n",
    "    # Create a custom aggregation function to fill in values based on conditions\n",
    "    def fill_values(column):\n",
    "        if column[column > 0].empty:\n",
    "            return None\n",
    "        return column[column > 0].values[0]\n",
    "\n",
    "\n",
    "\n",
    "def test_get_day_of_week():\n",
    "    df_train = pd.read_csv(\"train_data.csv\")\n",
    "    df_test = pd.read_csv(\"test_data.csv\")\n",
    "\n",
    "    df_days = pd.DataFrame({'local_numeric_day': [1,2,3,4,5,6,7], 'local_day':['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']})\n",
    "    cols = ['local_numeric_day', 'local_day']\n",
    "    try:\n",
    "        print(\"Trying\")\n",
    "        df_train = Preprocessor.get_day_of_week(df_train).sort_values(by='local_numeric_day')[cols]\n",
    "        df_test = Preprocessor.get_day_of_week(df_test).sort_values(by='local_numeric_day')[cols]\n",
    "        print(\"Try ok\")\n",
    "        assert_frame_equal(df_train, df_test)\n",
    "        print(\"The DataFrames are equal.\")\n",
    "    except AttributeError: # str type 'datetime' column doesnt have datetime built-in function\n",
    "        try:\n",
    "            print(\"Caught attribute error\")\n",
    "            df_train['datetime'] = df_train['datetime'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "            df_test['datetime'] = df_test['datetime'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "            df_train = Preprocessor.get_day_of_week(df_train).sort_values(by='local_numeric_day')[cols]\n",
    "            df_test = Preprocessor.get_day_of_week(df_test).sort_values(by='local_numeric_day')[cols]\n",
    "            print(\"Exception ok\")\n",
    "            assert_frame_equal(df_train, df_test)\n",
    "            print(\"The exception DataFrames are equal.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error message: {e}\") \n",
    "\n",
    "Preprocessor = Preprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_get_day_of_week()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "\n",
    "df_train = pd.read_csv(\"train_data.csv\")\n",
    "df_test = pd.read_csv(\"test_data.csv\")\n",
    "cols = ['local_numeric_day', 'local_day']\n",
    "\n",
    "df_train['datetime'] = df_train['datetime'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "df_test['datetime'] = df_test['datetime'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "df_train = Preprocessor.get_day_of_week(df_train).sort_values(by='local_numeric_day')[cols].drop_duplicates()\n",
    "df_test = Preprocessor.get_day_of_week(df_test).sort_values(by='local_numeric_day')[cols].drop_duplicates()\n",
    "print(\"Exception ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_frame_equal(df_train, df_test)\n",
    "print(\"The DataFrames are equal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('project')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train_data.csv\")\n",
    "df_test = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.datetime.dtypes == object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.date.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.read_csv('validation/result_20230808.csv')\n",
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.steps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample dictionary for the new row\n",
    "new_row_dict = {'A': 10, 'B': 20, 'C': 30}\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df = pd.DataFrame(columns=['A', 'B', 'C'])\n",
    "\n",
    "# Add the new row to the DataFrame using .loc[]\n",
    "df.loc[len(df)] = new_row_dict\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_values = np.array([10, 15, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_values[[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "q = joblib.load('sarsa_crypto.joblib')\n",
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = (0,0,0,3)\n",
    "\n",
    "q[state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "array = np.array([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "])\n",
    "\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "random.choice(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state) -> tuple[int, float]: \n",
    "\n",
    "\tglobal Sarsa\n",
    "\n",
    "\tr_var = random.random()\n",
    "\tif r_var < Sarsa.epsilon:\n",
    "\t\tprint(\"random\")\n",
    "\t\tbest_action = np.where(Sarsa.Q[state] == random.choice(Sarsa.Q[state]))[0][0]\n",
    "\t\tbest_value = Sarsa.Q[state][best_action]\n",
    "\telse:\n",
    "\t\tbest_action = np.argmax(Sarsa.Q[state])\n",
    "\t\tbest_value = Sarsa.Q[state][best_action]\n",
    "\n",
    "\treturn best_action, best_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sarsa: \n",
    "    def __init__(self):\n",
    "        self.Q = None \n",
    "        self.epsilon = 0.5\n",
    "\n",
    "Sarsa = Sarsa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sarsa.Q = np.random.rand(2,5,7,288,3)\n",
    "Sarsa.Q.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_state = (0,0,0,0)\n",
    "\n",
    "for i in range(10):\n",
    "    action, q_value = policy(current_state)\n",
    "    print(action, q_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.zeros((5,7,288,3))\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_table = Q[..., np.newaxis]\n",
    "price_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = pd.read_csv(\"project-2/validation/preprocessed_data.csv\")\n",
    "df_reward_stats = pd.read_csv(\"project-2/validation/reward_stats_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reward_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_price_table(df, Q):\n",
    "    # get the unique value of each column for each state \n",
    "    price_table = Q[..., np.newaxis]\n",
    "    print(\"Price table dimension:\", price_table.shape)\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    df['label_encoded_time'] = encoder.fit_transform(df[['encoded_time']])\n",
    "    df = df[['week_of_month', 'local_numeric_day', 'label_encoded_time', 'average_period_price']]\\\n",
    "        .groupby(['week_of_month', 'local_numeric_day', 'label_encoded_time'])\\\n",
    "        .mean().reset_index()\n",
    "    \n",
    "    print(f\"\\n{df.columns}\\n\")\n",
    "\n",
    "    # Iterate over the rows of the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        week_index = int(row['week_of_month']-1)\n",
    "        day_index = int(row['local_numeric_day']-1)\n",
    "        time_index = int(row['label_encoded_time']-1)\n",
    "        value = row['average_period_price']\n",
    "        print(week_index, day_index, time_index, value)\n",
    "        price_table[week_index, day_index, time_index] = value\n",
    "\n",
    "    return price_table\n",
    "\n",
    "\n",
    "def pivot_rewards_table(df):\n",
    "    df_sell_rewards = df_reward_stats['sell_rewards'][['mean']].copy()\n",
    "    df_buy_rewards = df_reward_stats['buy_rewards'][['mean']].copy()\n",
    "    df_sell_rewards.columns = ['sell_rewards']\n",
    "    df_buy_rewards.columns = ['buy_rewards']\n",
    "    df_nested_rewards = pd.concat([df_reward_stats[['week_of_month', 'local_numeric_day', 'encoded_time']], df_sell_rewards, df_buy_rewards], axis=1)\n",
    "\n",
    "    # rename column to remove the tuple-like hierachy syntax for easier retrieve\n",
    "    rename_cols = ['week_of_month', 'local_numeric_day', 'encoded_time', 'sell_rewards', 'buy_rewards']\n",
    "    df_nested_rewards.columns = rename_cols\n",
    "\n",
    "    df_pivoted_rewards = pd.pivot_table(df_nested_rewards, values=['sell_rewards', 'buy_rewards'], index=['week_of_month', 'local_numeric_day', 'encoded_time'],\n",
    "                                aggfunc=fill_values).reset_index()\n",
    "    df_pivoted_rewards = df_pivoted_rewards.rename(columns={'sell_rewards': 'sell_action', 'buy_rewards': 'buy_action'})\n",
    "\n",
    "    # assign reverse action reward for NaN value \n",
    "    df_pivoted_rewards['buy_action'] = df_pivoted_rewards['buy_action'].fillna(df_pivoted_rewards['sell_action']*-1)\n",
    "    df_pivoted_rewards['sell_action'] = df_pivoted_rewards['sell_action'].fillna(df_pivoted_rewards['buy_action']*-1)\n",
    "    df_pivoted_rewards['no_action'] = 0\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    df_pivoted_rewards['label_encoded_time'] = encoder.fit_transform(df_pivoted_rewards[['encoded_time']])\n",
    "\n",
    "    # get the unique value of each column for each state \n",
    "    state_unique_counts = df_pivoted_rewards.nunique()\n",
    "\n",
    "    # initialize shape size\n",
    "    state_array_shape = tuple(state_unique_counts[:3])\n",
    "    # add 3 unique actions \n",
    "    state_array_shape += (3 ,)\n",
    "    print(\"State array shape:\", state_array_shape)\n",
    "\n",
    "    # create the array with the initialized shape size \n",
    "    state_array = np.zeros(state_array_shape)\n",
    "\n",
    "    return df_pivoted_rewards, state_array\n",
    "\n",
    "\n",
    "def create_reward_table(df_pivoted_rewards, state_array) -> tuple[np.array, np.array]:\n",
    "    # start padding reward value into each state respectively\n",
    "    # Iterate over the rows of the DataFrame\n",
    "    for index, row in df_pivoted_rewards.iterrows():\n",
    "        week_index = row['week_of_month']-1\n",
    "        day_index = row['local_numeric_day']-1\n",
    "        time_index = row['label_encoded_time']-1\n",
    "        value = [row['buy_action'], row['sell_action'], row['no_action']]\n",
    "        state_array[week_index, day_index, time_index] = value\n",
    "\n",
    "    # 25/7/2023: Temporarily add in the two dimensional holding or not holding into the state.\n",
    "    # In the future, all this categorical or continuous factor should be written in a scalable way instead of so ad hoc\n",
    "    holding_array = np.array([[0,1]]).T\n",
    "    reward_table  = holding_array[:, np.newaxis, np.newaxis, np.newaxis, :] + state_array\n",
    "\n",
    "    # assign state array to be reward array for easier reference\n",
    "    Q = np.zeros(reward_table.shape)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nReward table generated!\")\n",
    "        print(\"Reward table size:\", reward_table.shape)\n",
    "        print(\"Reward table value peek:\", reward_table[0,0,0,0,0])\n",
    "\n",
    "        print(\"\\nQ table initialized!\")\n",
    "        print(\"Q table size:\", Q.shape)\n",
    "        print(\"Q table value peek:\", Q[0,0,0,0,0])\n",
    "\n",
    "    return reward_table, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "df_result = create_price_table(df, Q)\n",
    "df_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_table = Q[..., np.newaxis]\n",
    "price_table.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivoted_rewards, state_array = pivot_rewards_table(df_reward_stats)\n",
    "print(state_array.shape)\n",
    "df_pivoted_rewards.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, Sarsa.Q = Preprocessor.create_reward_table(df_reward_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['week_of_month', 'local_numeric_day', 'label_encoded_time', 'average_period_price']]\\\n",
    "    .groupby(['week_of_month', 'local_numeric_day', 'label_encoded_time'])\\\n",
    "    .mean().reset_index()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_table.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the rows of the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    week_index = int(row['week_of_month']-1)\n",
    "    day_index = int(row['local_numeric_day']-1)\n",
    "    time_index = int(row['label_encoded_time']-1)\n",
    "    value = row['average_period_price']\n",
    "    print(week_index, day_index, time_index, value)\n",
    "    #price_table[week_index, day_index, time_index] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "encoder  = LabelEncoder()\n",
    "\n",
    "df['label_encoded_time'] = encoder.fit_transform(df[['encoded_time']])\n",
    "df = df[['week_of_month', 'local_numeric_day', 'label_encoded_time', 'average_period_price']]\\\n",
    "    .groupby(['week_of_month', 'local_numeric_day', 'label_encoded_time'])\\\n",
    "    .mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    time_index = int(row['label_encoded_time']-1)\n",
    "    print(\"Price:\", time_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib \n",
    "\n",
    "sarsa_model = joblib.load('project-2/sarsa_crypto.joblib')\n",
    "sarsa_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [10, 20, 15, 25, 30, 18, 12, 40, 22, 35]\n",
    "\n",
    "# Sort the data in reverse and get the sorted indices\n",
    "sorted_indices = [index for index, _ in sorted(enumerate(data), key=lambda x: x[1], reverse=True)]\n",
    "\n",
    "print(\"Original Data:\", data)\n",
    "print(\"Sorted Indices:\", sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "\n",
    "keep_top_n_steps = 2\n",
    "\n",
    "class test:\n",
    "    def __init__(self):\n",
    "        self.df_steps=pd.DataFrame(columns=['Step'] + [f'Top_{i+1}' for i in range(keep_top_n_steps)]) \n",
    "        self.df_rewards=pd.DataFrame(columns=['Rewards'] + [f'Top_{i+1}' for i in range(keep_top_n_steps)])\n",
    "        self.top_n_total_rewards = [0]\n",
    "        self.keep_top_n_steps=10 if keep_top_n_steps is None else keep_top_n_steps\n",
    "        self.keep_top_n_steps=[0]*self.keep_top_n_steps\n",
    "\n",
    "    # Update and keep the top n values \n",
    "    def update_top_n_values(self, rewards:list[float], steps:list[int]):\n",
    "        for index, _ in enumerate(self.top_n_total_rewards, start=1):            \n",
    "            if sum(rewards) > self.top_n_total_rewards[-1]:\n",
    "                print(\"Replacing\")\n",
    "                self.top_n_total_rewards.pop()\n",
    "                self.top_n_total_rewards.append(sum(rewards))\n",
    "                self.df_rewards.iloc[:, -1] = rewards\n",
    "                self.df_steps.iloc[:, -1] = steps       \n",
    "\n",
    "            self.top_n_total_rewards.sort(reverse=True)\n",
    "            sorted_indices = [\n",
    "                index for index, _ \n",
    "                in sorted(enumerate(self.top_n_total_rewards), key=lambda x: x[1], reverse=True)\n",
    "            ]\n",
    "            print(\"total rewards:\", self.top_n_total_rewards)\n",
    "            print(\"Sorted indices:\", sorted_indices)\n",
    "\n",
    "            # re-sort df_steps, df_rewards based on the sorted_indices \n",
    "            self.df_steps = self.df_steps.iloc[:, sorted_indices]\n",
    "            self.df_rewards = self.df_rewards.iloc[:, sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'df_steps': Empty DataFrame\n",
       " Columns: [Step, Top_1, Top_2]\n",
       " Index: [],\n",
       " 'df_rewards': Empty DataFrame\n",
       " Columns: [Rewards, Top_1, Top_2]\n",
       " Index: [],\n",
       " 'top_n_total_rewards': [0],\n",
       " 'keep_top_n_steps': [0, 0]}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = test()\n",
    "tester.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_steps_values [1, 1, 1, 1, 1]\n",
      "random reward values [-1, 1, 0, -1, 1] \n",
      "\n",
      "total rewards: [0]\n",
      "Sorted indices: [0]\n",
      "random_steps_values [-1, 1, -1, -1, -1]\n",
      "random reward values [0, 0, 0, -1, 1] \n",
      "\n",
      "total rewards: [0]\n",
      "Sorted indices: [0]\n",
      "random_steps_values [0, 0, -1, 0, 0]\n",
      "random reward values [-1, 0, 1, -1, -1] \n",
      "\n",
      "total rewards: [0]\n",
      "Sorted indices: [0]\n",
      "random_steps_values [1, 0, 0, 0, 1]\n",
      "random reward values [-1, 0, -1, -1, -1] \n",
      "\n",
      "total rewards: [0]\n",
      "Sorted indices: [0]\n",
      "random_steps_values [0, 1, 0, -1, -1]\n",
      "random reward values [0, 1, -1, 0, 1] \n",
      "\n",
      "Replacing\n",
      "total rewards: [1]\n",
      "Sorted indices: [0]\n",
      "random_steps_values [0, 0, 0, -1, -1]\n",
      "random reward values [0, 0, 1, 0, -1] \n",
      "\n",
      "total rewards: [1]\n",
      "Sorted indices: [0]\n",
      "random_steps_values [-1, 1, 0, 0, 0]\n",
      "random reward values [1, 1, 0, -1, 1] \n",
      "\n",
      "Replacing\n",
      "total rewards: [2]\n",
      "Sorted indices: [0]\n",
      "random_steps_values [-1, 0, 0, 0, 1]\n",
      "random reward values [-1, 0, -1, -1, -1] \n",
      "\n",
      "total rewards: [2]\n",
      "Sorted indices: [0]\n",
      "random_steps_values [1, 0, 1, 1, -1]\n",
      "random reward values [1, 0, 0, -1, 0] \n",
      "\n",
      "total rewards: [2]\n",
      "Sorted indices: [0]\n",
      "random_steps_values [-1, -1, 1, 1, -1]\n",
      "random reward values [-1, 0, 0, 1, 1] \n",
      "\n",
      "total rewards: [2]\n",
      "Sorted indices: [0]\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "test_episode = 10\n",
    "test_values = 5\n",
    "for episode in range(test_episode):\n",
    "    random_steps_values = [random.choice([-1, 0, 1]) for _ in range(test_values)]\n",
    "    random_rewards_values = [random.choice([-1, 0, 1]) for _ in range(test_values)]\n",
    "    print(\"random_steps_values\", random_steps_values)\n",
    "    print(\"random reward values\", random_rewards_values, \"\\n\")\n",
    "    tester.update_top_n_values(random_rewards_values, random_steps_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rewards</th>\n",
       "      <th>Top_1</th>\n",
       "      <th>Top_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Rewards, Top_1, Top_2]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester.df_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_top_n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steps=pd.DataFrame({f'Step_Top_{i+1}': [0]*keep_top_n_steps for i in range(keep_top_n_steps)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step_Top_1</th>\n",
       "      <th>Step_Top_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Step_Top_1  Step_Top_2\n",
       "0           0           0\n",
       "1           0           0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_steps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
